# 原神剧情 QA 系统 - 项目进度计划

> 最后更新：2026-01-21

## 架构概览

采用 **LlamaIndex + Mem0** 混合架构：
- **LlamaIndex**：剧情知识库的构建和检索
- **Mem0**：用户交互的记忆管理

```
用户查询 → Mem0（个性化上下文）→ LlamaIndex（剧情检索）→ LLM → 响应
```

## 技术选型

| 组件 | 推荐方案 | 备选方案 |
|------|---------|---------|
| LLM | Claude Sonnet 4.5 / GPT-4 | Qwen2.5-72B（本地部署）|
| 嵌入模型 | BAAI/bge-base-zh-v1.5 | text-embedding-3-small |
| 向量数据库 | Qdrant（开源自托管）| Chroma / Pinecone |
| 图数据库 | Neo4j Community | Memgraph |
| 框架 | LlamaIndex + Mem0 | LangChain + Mem0 |

---

## 分阶段实施路线

### 第一阶段：基础 RAG 系统（1-2 周）

**目标**：实现基于向量检索的基础问答功能

**任务清单**：
- [ ] 搭建项目环境，安装依赖（LlamaIndex, Qdrant, BGE-zh）
- [ ] 实现数据加载器：解析 Data/ 目录下的剧情文本
- [ ] 设计分块策略：按对话轮次或场景切换分块
- [ ] 配置中文嵌入模型（BAAI/bge-base-zh-v1.5）
- [ ] 构建 Vector Store Index
- [ ] 实现基础问答 API
- [ ] 编写测试用例，评估检索质量

**测试方法**：
- [ ] 构建评测数据集（见下方测试方法章节）
- [ ] 使用 LlamaIndex 内置评估器测试 Faithfulness、Relevancy
- [ ] 人工抽样验证 Top-K 检索结果相关性
- [ ] 记录基线指标：Recall@5, MRR, 响应延迟

**交付物**：
- 可运行的基础 RAG 系统
- 基线性能报告

---

### 第二阶段：知识图谱增强（2-3 周）

**目标**：构建人物关系图谱，支持关系类查询

**任务清单**：
- [ ] 设计原神剧情 Schema
  - 实体：Character, Location, Organization, Event, Item
  - 关系：BELONGS_TO, LOCATED_IN, KNOWS, PARTICIPATES_IN, MENTIONED_IN
- [ ] 使用 Property Graph Index 提取实体和关系
- [ ] 配置实体去重规则（处理角色别名）
- [ ] 集成 Neo4j 存储图数据
- [ ] 实现混合检索策略（向量 + 图遍历）
- [ ] 支持 Cypher 查询接口

**测试方法**：
- [ ] 实体提取准确率：人工标注 50 个段落，计算 Precision/Recall
- [ ] 关系提取准确率：验证三元组正确性
- [ ] 关系查询测试集：构建 20+ 关系类问题（如"恰斯卡认识哪些角色？"）
- [ ] A/B 对比：纯向量检索 vs 混合检索

**交付物**：
- Neo4j 中的剧情知识图谱
- 混合检索 API
- 图谱可视化截图

---

### 第三阶段：记忆系统集成（1-2 周）

**目标**：实现多轮对话的上下文连贯性和个性化

**任务清单**：
- [ ] 集成 Mem0 作为记忆层
- [ ] 配置记忆隔离：user_id（跨会话）、run_id（单会话）
- [ ] 实现记忆提取：从对话中自动提取用户偏好
- [ ] 实现记忆更新：ADD/UPDATE/DELETE 操作
- [ ] 测试多轮对话连贯性

**测试方法**：
- [ ] 多轮对话测试集：设计 10 组连续对话场景
- [ ] 指代消解测试："她后来怎么样了？"能否正确关联上文
- [ ] 记忆持久化测试：跨会话验证用户偏好是否保留
- [ ] 记忆冲突测试：验证矛盾信息的更新逻辑

**交付物**：
- 完整的多轮对话系统
- 记忆管理 API

---

### 第四阶段：优化与部署（1 周）

**目标**：性能调优和生产就绪

**任务清单**：
- [ ] 分块策略优化：基于评估结果调整 chunk_size
- [ ] 检索参数调优：top_k, similarity_threshold
- [ ] 元数据丰富化：章节编号、任务名称、涉及角色
- [ ] 搭建 Web UI 或 REST API
- [ ] 编写用户文档

**测试方法**：
- [ ] 端到端延迟测试：P50/P95/P99 响应时间
- [ ] 并发压力测试（如适用）
- [ ] 用户验收测试：邀请 3-5 人试用并收集反馈

**交付物**：
- 生产就绪的 QA 系统
- 用户文档

---

## 测试方法详述

### 1. 评测数据集构建

**核心原则**：评测集应覆盖系统的核心能力，而非追求大而全。

**推荐构建方式**：

| 类别 | 数量 | 示例 |
|------|------|------|
| 事实查询 | 20 | "派蒙第一次见到伊法是在哪里？" |
| 关系查询 | 20 | "恰斯卡属于哪个部族？" |
| 事件追踪 | 15 | "秘源机兵袭击事件的经过是什么？" |
| 跨章节推理 | 10 | "从第0章到第2章，玩家的主要目标是什么？" |
| 多轮对话 | 10组 | 连续 3-5 轮的对话场景 |

**构建流程**：
1. 从 Data/ 中随机抽取 10 个章节
2. 人工阅读后编写问题和标准答案
3. 标注答案来源（章节、行号）
4. 区分"可直接检索"和"需要推理"两类

### 2. 自动化评估指标

**检索质量**（LlamaIndex 内置）：
- **Faithfulness**：答案是否基于检索内容，无幻觉
- **Relevancy**：检索内容与问题的相关性
- **Context Precision**：Top-K 中相关文档的比例

**检索效率**：
- Recall@K：标准答案出现在 Top-K 的比例
- MRR (Mean Reciprocal Rank)：标准答案首次出现的排名

**端到端质量**（需 LLM 评估或人工）：
- 答案正确性：与标准答案的一致程度
- 答案完整性：是否遗漏关键信息

### 3. 人工评估流程

**抽样策略**：每个阶段随机抽取 20 个问答对进行人工评审

**评分维度**（1-5 分）：
- 正确性：答案是否准确
- 相关性：是否回答了用户的问题
- 流畅性：表达是否自然
- 引用质量：是否合理引用原文

### 4. 回归测试

每次迭代后运行完整评测集，确保：
- 新功能未破坏已有能力
- 核心指标无明显下降（允许 5% 波动）

---

## 数据概览

- **数据来源**：Data/ 目录
- **任务数量**：约 10 个主线任务文件夹（1600-1608）
- **数据格式**：Markdown 风格的对话文本
  - 章节标题（# 归途 - 第0章：墟火）
  - 剧情简介
  - 对话内容（角色名：对话内容）
  - 玩家选项

---

## 开发日志

### 2026-01-21
- 完成技术报告分析
- 明确采用 LlamaIndex + Mem0 混合架构
- 制定分阶段实施计划（预计总周期 5-8 周）
- 补充详细测试方法
